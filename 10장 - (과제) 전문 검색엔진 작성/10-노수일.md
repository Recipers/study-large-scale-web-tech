# 10. [과제] 전문 검색엔진 작성
- 기초, 상세부분 작성, 속도와 정확성 추구
### 대규모 데이터 처리의 대표 기술
- 검색엔진 개발에 도전
- 검색엔진이 언뜻 보면 어려울 순 있어도 내부에는 해시와 같은 데이터 구조로 일단 실현할 수 있음
- 대규모 데이터 대상인 경우는, 다양한 발전 필요성이 있지만 기본적인 부분은 동일
## 10-27. [과제] 하테나 북마크 전문 검색 만들기
### 전문 검색엔진 개발
#### [과제] 하테나 북마크에 작성된 최근 1만 건의 엔트리를 대상으로 한 전문 검색 만들기
- 대상은 최근 엔트리 1만 건
- 검색어를 포함하는 엔트리를 반환
- 반환하는 내용은 URL, 타이틀을 포함할 것
- 가능하면 스니핏도 표시할 것
- 작성일자순으로 정렬
- 추가하면 좋은 것
    - 검색조건 추가 : AND / OR 검색에 대응, 카테고리 분류에 대응
    - 속도와 정확성 추구 : 실용적인 검색속도, 검색누락이나 false-positive 회피
### 과제내용
- "마이 북마크 검색"과 비슷한 것을 만들어 보는 것
- 북마크 데이터를 대상으로 검색어를 포함하는 엔트리를 반환하는 프로그램
- URL 뿐만 아니라 본문에 검색어가 포함되어 있는지 여부도 체크해서 해당하는 엔트리 반환
- 검색 결과로는 엔트리의 URL과 타이틀을 반환
- 여유가 있다면 스니핏 출력
- 작성일자 순으로 정렬
- 최신 5건 혹은 10건씩 출력
#### 과제를 해결하면 어떤 점이 좋은가?
- RDBMS의 한계를 돌파하는 등 다양한 응용을 할 수 있음
### 샘플 데이터 형식과 데이터 크기
- 샘플 데이터
    1. URL이나 타이틀 등 엔트리의 기본 데이터가 10,000건 기록되어 있는 텍스트
    2. 각 엔트리의 본문 텍스트 파일 10,000개
- 왼쪽 탭 부터
    - 엔트리 ID
    - 카테고리 ID
    - URL
    - 타이틀
### 사전의 구성
- Dictionary, Postings
- Dictionary + Postings를 만드는 것이 과제
- 단어를 기반으로 한 Dictionary 만들기
- Dictionary는 AC법, MeCab
- Postings의 압축은 VB Code 구현 사용
### 인터페이스
- 명렬줄에서 실행
- 대화형 인터페이스
### 기본적인 부분 + 심화 구현
- 세 가지 측면으로 더 깊이 있게 구현했으면 함
    - 전문 검색을 구현한다
    - AND / OR 검색을 할 수 있다
    - 카테고리에 따라 분류할 수 있다
### 속도와 정확성으로 승부
- 샘플 쿼리로 100개 정도의 검색어를 정하고 해당 쿼리를 입력으로 검색엔진 시스템 평가
- 속도와 정확성으로 승부
- 샘플 쿼리에 대한 검색결과 상위 5건을 평가
    - 검색시간
    - 정확성
- 100개의 샘플 쿼리를 날렸을 때 모든 검색결과를 반환하는데 몇 초 걸리는지 체크
- 상위 5건이 검색누락을 일으키지는 않았는지
- 일자순 정렬이 누락되지 않았는지
- false-positive(원래 나와서는 안 되는 잘못된 검색결과)를 반환하지는 않는지
## 10-28. 응답 사례와 사고방식
### 응답 사례
- 역 인덱스를 만들어서 디스크에 기록하는 indexer.pl
- 대화 프롬프트로 검색하는 searcher.pl
    - 스니핏도 출력
### indexer.pl 구현
- indexer.pl 구현소스
- Dictionary는 MeCab을 사용해서 형태소 기반 사전을 만듬
- 역 인덱스는 Perl의 해시로 만듬
- Postings List의 압축은 차분을 구해서 VB Code를 적용
    - Array::Gap 이라는 라이브러리 사용
- 소스코드 내용
    - 역 인덱스가 구축되면 Storable이라는 Serialize / Deserialize 라이브러리를 사용해서 디스크에 해시 기록
    - 기본 데이터 파일로 부터 타이틀, URL 등을 읽어냄
    - MeCab으로 전문을 형태소 분석, 역 인덱스를 만듬
    - 역 인덱스인 PostingsLIst를 Array::Gap으로 압축
    - 인덱스를 Storable로 디스크에 기록
### searcher.pl 구현
- 입력으로 주어진 데이터 파일을 읽어들임
- indexer.pl로 만든 인덱스 파일을 로드
- 로드된 역 인덱스는 그대로 Perl의 해시로 사용
- 소스코드 내용
    - 기본 데이터 파일로부터 타이틀 등을 읽어냄
    - 역 인덱스를 메모리에 로드
    - Term::ReadLine으로 대화 프롬프트 실행
    - 역 인덱스에서 검색
    - 얻기, 결과표시
        - 스니핏 출력
### 개선할 수 있는 점은?
- AND / OR 검색 구현
    - 복수의 쿼리 단어를 얻었다면
    - 각각의 쿼리 단어에 대응하는 Postings List에 출현하는 공통 문서 ID의 교집합 -> AND
    - 각각의 쿼리 단어에 대응하는 Postings List에 출현하는 공통 문서 ID의 합집합 -> OR
- searcher.pl로 검색어도 분해한다
    - 이번 과제는 AND / OR 검색을 지원하지 않으므로 검색어를 그대로 역 인덱스에 집어넣음
    - 실제로는 쿼리 단어도 형태소 분석한 후 역 인덱스로 검색하는 것이 정확도 향상
### Twitter의 스케일 아웃 전략
#### 기본 전략과 서비스 특징에 맞는 전략
- Twitter가 어떤 식으로 부하분산을 하고 있는가
- 파티셔닝 등으로 데이터를 분할해서 조정하는 것이 그 기본임을 반복해서 언급
- MySQL을 확장
- MySQL + memcached에 파티셔닝
- Twitter는 트윗 작성일시를 축으로 한, 시간축을 이용해서 파티셔닝
- fan out 이라고 하는 메일 전송과 비슷한 아키텍쳐를 MySQL + memcached에 채택해서 실시간성을 잃지 않고 실현
