# 9. 전문 검색기술 도전
- 대규모 데이터 처리의 노하우
### 왜 검색인가?
- 응용을 적용하기 쉬운 기술
- 검색엔진은 내부에 다양한 알고리즘이 응용되고 있고, 원리를 응용해서 적용하기 쉬움
- 최근의 하드웨어는 굉장히 고성능이라 작은양의 데이터는 충분한 속도의 결과를 반환
    - 대규모이면 만족할 만한 속도가 나오지 않음
- 하테나에서 만든 검색 시스템 소개 및 실제 사례 이미지화
    - 구현부 제외
## 9-24. 전문 검색기술의 응용범위
### 하테나의 데이터로 검색엔진 만들기
- 검색엔진의 중요 요소인 역 인덱스에 대해 설명
### 하테나 다이어리의 전문 검색
- 검색 서비스 이외에 검색 시스템 이용
- 하테나 다이어리의 전문을 검색 대상으로 해서 하테나 키워드로 이를 검색 가능하게 하는 시스템을 개발했음
- 하테나 키워드에 포함되어 있는 단어만을 검색할 수 있는 시스템
#### 전에는 RDB로 처리했다
- 전에는 이 기능을 RDB로 처리
- 누군가 블로그에 글을 작성 했을 때 해당 글에 포함되어있는 키워드를 전부 추출
- 이 단어와 블로그의 연관성을 DB 레코드로 저장
- 확장성 측면에서 완전히 파탄을 가져옴
    - 레코드 수가 너무 많았음
    - 무거워지고, 특정 데이터 이후에는 보이지 않는 등의 제한이 생겨버림
#### 검색기술의 응용
- 검색엔진을 만들어서 검색함으로써 문제를 회피
- 사용자가 검색쿼리를 날리는 게 아니라 다른 곳에 날려지고 이를 검색 시스템에 입력해서 결과를 얻음
- 일자 순으로만 정렬을 하면 되는 시스템
    - 컴팩트하고 빠르게 구현이 가능했음
- 하테나 다이어리의 문서만을 검색하는 시스템
    - 문서ID를 하테나 다이어리의 사양에 특화시킨 방법으로 저장함으로써 빠른 속도 도모
### 하테나 북마크의 전문 검색
- 세세한 요구를 만족시키는 시스템
#### 마이 북마크 검색
- 자신이 북마크한 사이트만을 대상으로 한 전문 검색엔진
- 다이어리 전문 검색과의 차이는 시스템의 규모나 이용 목적
- 검색엔진의 기능적인 면에서 스니핏도 나타나도록 되어 있음
- 스니핏을 실현하려면 검색어가 문서 내의 어느 위치에 있는 단어와 매칭되는지를 기록할 필요가 있음
    - 고속으로 수행하려면 데이터 구조가 복잡해짐
- 시스템의 규모나 이용 목적이 다르다는 점
    - 개인이 북마크한 개인 데이터로부터 검색하는 시스템
    - 비교적 작은 데이터이지만 데이터베이스 측면에서는 역시나 한계가 있었음
- 사용자가 북마크를 추가하는 타이밍에 맞춰 각 사용자별로 검색 인덱스를 준비해두고 이를 갱신
- 검색 시에는 해당 사용자의 인덱스에서만 검색
## 9-25. 검색 시스템의 아키텍처
### 검색 시스템이 완성되기까지
- 전문검색은 해야 할 것이 매우 많음
1. 크롤링
    - 검색할 대상문서를 가져오는 것
2. 저장
    - 가져온 문서를 어떻게 저장할 것인가라는 문제
    - 다중화 등
3. 인덱싱
    - 가져온 문서로부터 인덱스를 구축
    - 인덱스는 고속으로 검색하기 위한 구조
4. 검색
    - 검색쿼리를 포함하는 문서가 검색결과로서 반환
5. 스코어링
    - 순서를 어떻게 표시할 것인가
6. 결과표시
#### 이번 설명대상
- 인덱싱과 검색에 대해 집중 강의
### 다양한 검색엔진
- 검색엔진 시스템은 과거부터 많이 개발되어 오고 있음
    - grep (생각하기에 따라 전문검색)
    - Namazu
    - Apache Lucene
    - Shunsaku
    - Senna
    - Sedue
    - Lux
### 전문 검색의 종류
- grep형, Suffix형, 역 인덱스형
#### grep형
- 검색 대상 문서를 처음부터 전부 읽어가는, 가장 단순한 아키텍처
- 검색 대상인 텍스트의 길이를 m, 검색어를 n이라고 했을 때 O(mn)만큼의 시간이 걸림
- KMP(knuth-Morris-Pratt), BM(Boyer-Moore)법 등 어느 정도 계산량을 개선한 방법이 있음
    - 단순 검색 : O(mn)
    - KMP : O(m+n)
    - BM : 최악 -> O(mn), 최선 O(n/m)
- 좋은 점으로는 즉시성이 있음
    - 문서가 갱신되더라도 바로 검색할 수 있음
- 검색 누락이 없음
- 병렬화하기 매우 간단함
- 대규모 환경에서 쉽게 만들려고하면 다소 무리가 따름
#### Suffix형
- 검색 대상 전문을 검색 가능한 형태로 가지고 있음
- 데이터 구조로 Trie나 Suffix Array, Suffix Tree 등이 있음
- 문서를 검색 가능한 형태로 가지고 있고, 전부 메모리에 올릴 수 있는 형태
- 빠르게 검색할 수 있는 수단
- 이론적으로는 가능하나, 이 아키텍처를 가진 엔진은 구현하기 어려움
#### 역 인덱스형
- 현재 주류
- 단어와 문서를 연관짓는 것
- 역 인덱스를 문서와는 별개로 만들어야 함
- 검색하기 전에 인덱스를 전처리로 만들어야 함
- grep과 같이 문서가 변경되면 바로 검색결과도 바뀌는 형태의 구현은 할 수 없음
- 즉시성 측면에서는 뛰어나지 못함
- 구현 방법에 따라서는 검색누락이 생길 수 있음
- 인덱스를 압축함으로써 컴팩트하게 가져갈 수 있고 대규모화하기도 쉬움
- 구현도 적절한 공수로 끝낼 수 있어서 밸런스도 좋은 아키텍처
- 실제 시스템의 상당수가 채용하고 있음
## 9-26. 검색엔진의 내부구조
### 역 인덱스의 구조
- Dictionary+Postings
- 역 인덱스의 내부구조는 크게 Dictionary와 Postings라는 두 파트로 나뉨
- 역 인덱스 예시
    - 그림 1은 문서를 나타냄
    - 그림 2는 문서를 인덱스화 한 것
    - 그림 2의 좌측에 나열되어 있는 단어는 term
    - term의 집합이 Dictionary
    - term으로 포함하고 있는 문서는 몇 번인지를 나타내는 것이 우측의 배열, Postings
    - "하테나"를 포함하고 있는 문서는 어떤 것들이 있는지 찾기
        - Dictionary에서 "하테나"를 찾음
        - 이에 연결되어 있는 Postings를 얻음
- 인덱스를 보면 바로 어떤 문서에 어떤 단어가 포함되어있는지 알 수 있음
- term은 문서 내의 단어이고 문서를 검색할 수 있는 단위
- 역 인덱스는 term을 포함하는 문서를 즉시 발견할 수 있는 구조로 되어 있음
- Dictionary를 구성하는 데는 다양한 방법이 있음
### Dictionary 만드는 법
- 역 인덱스 작성법#1
- term을 어떻게 선택하느냐라는 문제가 있음
    - 미리 정해놓은 사전을 사용하는 방법
    - 8장의 과제에서 만든 AC법과 같은 것으로 단어를 분리하는 방법
    - 형태소 분석을 사용하는 방법
    - n-gram이라는 기법으로 문자를 적당한 단위로 나누고, 이를 term으로 다루는 방법
#### 언어의 단어를 term으로 하는 두 가지 방법
- 어떻게 해서 검색하고자 하는 대상 문서에 해당 단어가 있는지를 찾을 수 있는가에 관한 부분
    - 영어라면 공백으로 구분
    - 일본어는 공백이 없어서 문제가 있고, AC법을 사용하는 경우와 형태소 분석을 사용하는 경우 생각
#### 1. 사전과 AC법을 이용하는 방법
- 사전이 곧 검색 시스템의 단어공간이 됨
- 사전에 들어 있는 단어만 검색할 수 있음
- 사전으로 무엇을 사용할지에 따라 달라짐
- 앞서 소개한 하테나 키워드의 `포함하는 블로그 기능`
#### 2. 형태소 분석을 이용하는 방법(형태소를 단어로 간주해서 term으로 한다)
- 형태소 분석
    - 유형파악과 분리 기능을 함
    - 텍스트를 명사나 부사로 분할해서 품사를 분해하는 것을 "유형파악과 분리"라고 함
    - 이 원리에 따라 세세하게 나눈 각 단어를 형태소라고함
- 형태소 분석기는 문장을 형태소로 나워서 품사를 추정
- 품사 추정은 형태소 분석용 사전을 가지고 있는 경우가 있음
- 기계학습 등으로 예측하기도 함
- 형태소 분석기 사전은 직접 커스터마이징 할 수 있음
#### 검색누락
- 형태소를 사용할 경우와 같이 단어를 term, Dictionary의 개개의 요소로 하면 "검색누락" 문제가 발생할 가능성이 있음
- Gears of War, 에서 Gear는 사전에는 없음
- 이를 타당한가 문제로 볼 것인가
#### n-gram을 term으로 다루기
- n-gram, k-gram
- 텍스트를 n자씩 잘라낸 것
- abracadabra의 3-gram : abr, bra, rac ...
- n-gram으로 잘라낸 단위를 Dictionary의 term으로 다루는 방법이 있음
#### 쿼리도 동일한 규칙으로 분할하기
- "하테나"라고 검색할 경우 "하테", "테나"로 역 인덱스를 조회
- 두 개의 Postings가 얻어 지는데 양쪽에 포함된 문서번호를 구하는 처리
    - 교집합을 취한다
#### n-gram 분할 문제와 필터링
- n-gram으로는 이따금 잘못된 검색을 수행하는 문제가 있음
- 예시) 동경도 문제
    - 동경, 경도로 분할
    - 동경타워와 경도타워라는 문서를 인덱싱했다고 하면
    - 동경도로 검색하면 검색이 됨
    - 잘못 된 검색결과
    - 검색어를 포함하지 않는 결과를 반환하는 문제가 발생함
- 이 문제를 회피하기 위해 보통은 검색결과가 나온 후에 필터링을 수행함
- 실제로 검색결과를 조사해서 확인해보는 것이 필터링
- 필터링은 전문을 조사하므로, grep과 동일한 검색시간이 소요됨
#### 재현률(Recall)과 적합률(Precision)
- 어떤 결과가 나와야 타당한가?
    - 만든 사람이나 사용하는 사람의 주관에 의존하는 부분
- 좀 더 정량적인 평가를 내리기 위한 기준이 재현률과 적합률
- 어느 정도의 양, 결과를 반환하는가가 재현률
    - "하테나"로 검색했을 때 몇 건의 결과를 반환할 수 있는가
- 반환한 것 중 명백히 타당한 결과를 얼마나 반환하고 있느냐가 적합률
    - 반환한 결과에 얼마나 적합한 결과가 있는지
- 재현률과 적합률에는 상반관계가 있다
#### 검색 시스템 평가와 재현률/적합률
- 재현률/적합률을 사용하면 검색 시스템에 특정쿼리를 입력했을 때의 성능을 정량화 할 수 있음
- 형태소 분석은 검색되었으면 하는게 검색되지 않는 경우가 있음
    - 의도하지 않은 결과가 나오는 경우는 적으므로 적합률이 우선됨
- n-gram은 검색 누락은 발생하지 않지만 의도하지 않는 결과가 반환되는 경우가 있음
    - 재현률이 우선시되었다고 볼 수 있음
#### 지금까지의 내용 정리
- 검색엔진에도 여러 종류가 있음
- grep형, suffix형, 역 인덱스형
- 현재 주류는 역 인덱스형
- 역 인덱스형은 Dictionary + Postings 구조
- Dictionary 구성 에는 형태소 분석, n-gram이 있음
### Postings 작성법
- 역 인덱스 작성법#2
- 해당 단어를 포함하는 문서번호 또는 ID를 지니고 있는 배열
- 문서 ID만 단순하게 보유할 수 도 있고, 출현 위치를 저장하는 경우도 있음
    - 출현 위치까지 가지고 있는 경우는 Full Inverted Index 라고 함
    - 스니핏을 뽑을 때 단어가 문장 내 어디에 포함되어 있는지 바로 알 수 있음
    - 스코어링에도 도움이 됨
- n-gram을 이용할 때에 필터링을 할 경우에도 사용할 수 있음
#### 출현위치를 저장하지 않고 문서 ID만을 저장하는 타입
- 문서 ID만을 저장하는 타입
- Inverted File Index(역 파일 인덱스)
- 크기가 작고 구현도 용이해짐
- 문서ID는 정렬해둠
- 단순 증가/ 감소하는 정수열이 되므로 VBCode로 압축할 수 있음
    - 실제로 자주 사용됨
- key-value 스토어로 저장하기에 적합한 구조
- 다양한 검색엔진은 key-value 스토어를 독자적으로 지니고 있는 경우가 많음
#### 스코어링에 대한 보충
- 검색결과를 어떤 순서로 표시할 건지는 상당히 중요한 문제
- 검색결과의 랭킹을 결정하는 데에는 여러 기법을 생각해 볼 수 있음
- 단어가 문서내에서 중요도가 높다고 생각하면 문서의 순위를 높이는 일도 가능
    - TF(Term Frequency)/IDF(Inverse Document Frequency)를 이용해도 좋음
- 검색어가 많이 주어졌을 때 검색 대상 문서에 포함되어 있는 단어의 열을 보고, 문장과 주어진 단어열이 비슷한지 예측
- PageRank와 비슷하게 링크 피드백을 이용
