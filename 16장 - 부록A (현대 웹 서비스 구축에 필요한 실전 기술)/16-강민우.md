# 16장 - 부록A (현대 웹 서비스 구축에 필요한 실전 기술)
## 성장하는 서비스, 계속 증가하는 데이터
- `작업큐`, `스토리지 (RDB vs K-V 스토어)`, `캐시 시스템`, `계산 클러스터` 이 네 가지를 대해 다룸
- 작업큐 시스템은 요청의 비동기 처리에 사용
- 계속 증가하는 데이터를 어떻게 추가/변경할 지에 대한 대책으론 스토리지에 대해 다룸
- 웹 애플리케이션의 부하가 증가되었을 때 저비용으로 할 수 있는 대책으로 캐시
- MapReduce, Hadoop으로 대표되는 계산 클러스터의 개요에 대해 다룸

> **요약**
> - 작업큐 시스템 - TheSchwartz, Gearman -> 강의 1
> - 스토리지 선택 - RDB vs K-V 스토어 -> 강의 2
> - 캐시 시스템 - Squid vs Varnish 스토어 -> 강의 3
> - 계산 클러스터 - Hadoop 스토어 -> 강의 4

- - -
## 강의1 - 작업큐 시스템
### 웹 서비스와 요청
- 웹 서비스는 기본적으로 요청이 동기적으로 실행
	- 즉, 요청에 기인하는 모든 처리가 끝난 다음에 응답 반환
	- 서비스가 계속 성장하는 웹 서비스의 경우 데이터의 양이 많아질 경우 갱신 처리가 점점 무거워 짐
	- 이로인해 양호했던 성능도 시간이 지남에 따라 악화됨
- 이런 경우 작업큐 시스템을 사용함으로 나중으로 미뤄도 되는 처리를 비동기로 실행
	- ex) 하테나 북마크에서 `사용자가 URL을 북마크` 했을 때 처리를 작업큐 시스템에서 처리
	- 이에 따라 `URL 개요`, `키워드 추출`, `카테고리 판정` 등 **나중에 처리해도 되는 작업을 비동기**로 처리

### 작업큐 시스템 입문
- 가장 간단한 비동기 방법은 **비동기로 처리하고 싶은 부분을 독립된 스크립트로 해당 스크립트를 애플리케이션 내부에서 호출하는 방식**
	- 이 방법은 스크립트 시작과 초기화의 오버헤드가 커서 성능이 좋지는 않음
	- 또 일시적으로 대량의 비동기 처리를 실행시키려 하면 **그 수만큼의 프로세스를 실행**시켜 성능상 단점
	- 즉, 이 방식은 프로토타입이나 극히 소규모 애플리케이션에만 적용하는 것이 좋음
- 어느 정도 양이 있는 비동기 처리를 안정적으로 수행하려면 작업큐와 워커를 사용하는 작업큐 시스템이 좋음
	- 작업큐 시스템에서 작업큐에 실행하고자 하는 처리(작업)을 등록하고, 워커가 큐에서 작업을 추출해 실제 처리
	- 작업큐를 통해 일시적으로 대량의 처리가 등록되었을 대 부하의 변동을 흡수할 수 있음
	- 워커는 항상 실행해둠으로 작업을 처리할 때 초기화 오버헤드를 거의 없앨 수 있음
	<img src="../image/Pasted image 20250502215135.png" width="600" height="300">

### 하테나에서의 작업큐 시스템
- 하테나는 Perl로 구현된 `TheSchwartz`와 `Gearman`을 사용하고 있음

#### TheSchwartz
- MySQL과 같은 RDB를 사용하는 작업큐 시스템
- MySQL로 관리하다보니 매우 높은 신뢰성과 안정성을 확보하고 있음
- 비동기 처리에서 작업을 확실하게 처리해야 할 때 큰 장점이 됨
- 대신 속도가 느려 작업의 크기는 어느 정도 크게 하는 편이 좋음

#### Gearman
- TheSchwartz보다 가벼운 작업큐, 독자적인 데몬을 사용해 작업의 정보를 메모리에 저장
- 메모리를 사용하므로 성능이 더 좋음, 하지만 신뢰성에 대한 희생이 있음
- 이 작업큐는 클라이언트에서 작업을 투입할 때 다음의 세 가지 패턴을 취할 수 있음
	1. 동기적으로 순번대로 처리
	2. 동기적으로 병렬로 처리
	3. 비동기적으로 백그라운드로 처리
- TheSchwartz는 비동기만 사용할 수 있음, Gearman는 보다 더 유연하게 처리 가능
	- 특히 비동기적으로 병렬로 처리 가능

#### WorkerManager에 의한 워커 관리
- 하테나에서 자체적으로 개발
- 다음과 같은 기능이 있음
	- TheSchwartz와 Gearman을 래핑해 최소한의변경으로 양쪽의 대응 가능
	- 설정 파일로 워커 클래스 정의, 설정 파일만 수정해서 워커로서 사용할 클래스 변경 가능
	- 워커 프로세스의 라이프사이클 관리, 프로세스 관리, 데몬화 수행 - Apache prefork모델 참고
	- 등

### 로그 분석
- WorkerManager에서 워커가 작업을 처리했을 때의 타임스탬프 기록
- 처리시간과 지연시간을 측정해서 워커의 처리능력이 충분한지 확인

- - -
## 강의2 - 스토리지 선택 (RDB vs K-V 스토어)
### 증가하는 데이터를 어떻게 저장할까?
- 데이터량이나 스키마, 액세스 패턴에 맞는 스토리지를 선택하는 것은 중요

#### 웹 애플리케이션과 스토리지
- `스토리지` : `애플리케이션 데이터`를 역속적으로 혹은 일시적으로 저장하기 위한 기능

애플리케이션에서 다루는 다양한 데이터
- `원본 데이터` : 디지털 카메라 사진 데이터나 블로그 본문과 같이 본질적으로 없어질 수 없는 데이터
- `가공 데이터` : 원본 데이터를 가공함으로 생성된 액세스 랭킹이나 검색용 인덱스 등
- `사라져도 성능말고 문제가 없는 데이터` : 캐시 데이터

원본 데이터가 가장 중요하다. -> 서비스의 근본적인 신뢰성과 관련 있음
- 하지만 캐시와 같은 데이터는 신뢰성은 그다지 중요하지 않음

	<img src="../image/Pasted image 20250503012927.png" width="800" height="300">

#### 적절한 스토리지 선택의 어려움
- 저장하고자 하는 데이터의 특성에 맞는 스토리지를 선택해야 함
- 테라바이트 규모의 데이터를 서비스에 영향을 주지 않고 다른 스토리지로 옮겨 간다는 것은 어려움
- 특성에 맞는 스토리지를 선택하므로써 스토리지를 오래동안 사용하는 것이 좋음

### 스토리지 선택의 전제가 되는 조건
스토리지를 선택하기 위해 다음 여섯가지 지표를 살펴보자.
- 평균 크기
- 최대 크기
- 신규 추가 빈도
- 갱신 빈도
- 삭제 빈도
- 참조 빈도

크기에 요구되는 신뢰성, 허용할 수 있는 장애 레벨, 하드웨어나 예산도 중요한 포인트

### 스토리지의 종류
현재 사용가능한 스토리지
- RDB : MySQL, PostgreSQL 등
- 분산 K-V 스토어 : memcached, TokyoTyrant 등
- 분산 파일시스템 : MogileFS, GlusterFS, Lustre
- 그 외 : NFS 계열 분산 파일시스템, DRBD, HDFS

### RDB
- 표 형식으로 데이터 저장, SQL 언어로 데이터 조작 수행
- 다양한 데이터를 저장하거나 강력한 질의를 할 수 있음
- InnoDB와 MyISAM 비교와 Maria DB 이야기가 나옴
	- 하테나는 기본적으로 InnoDB 경우에 따라 MyISAM 사용

### 분산 key-value 스토어
- key-value 스토어는 key와 value 쌍을 저장하기 위한 심플한 스토리지, 분산 key-value 스토어는 key-value 스토어에 네트워크를 지원함으로써 다수의 서버로 확장시키는 기능
- key-value 스토어는 RDB에 비해 기능적으로는 부족하지만, 성능이 10~100배 이상
- 이때 당시 가장 유명한 스토어로는 memcached
	- 파일 시스템을 사용하지 않고 메모리 상에서만 동작

#### memcached
- 분산 알고리즘은 key의 해시값을 서버대수로 나눈 나머지를 사용하는 단순한 것에서 Consistent Hashing과 같은 비교적 복잡한 것까지 존재
- 하테나는 Perl과 Cache::Memcached::Fast 사용

#### TokyoTyrant - 생략

### 분산 파일 시스템
- 파일시스템의 특성상 보통은 어느 정도 이상인 크기의 데이터를 저장하는 데 적합
- 다음은 하테나에서 실제 사용하고 있는 분산 파일시스템이다.

#### MogileFS
- 비교적 작은 대량의 파일을 다룰 목적으로 Perl로 구현된 분산 파일시스템
- 아키텍처는 메타데이터를 수용하는 RDB, 스토리지 서버, 그 사이를 연결하는 전송 서버로 구성
- MogileFS는 대량의 수KB ~ 수십MB 정도의 이미지 파일을 효율적으로 저장히기 위한 시스템
- 기본적으로 대부분의 데이터는 추가된 다음 갱신되지 않고 참조하김나 하는 용도에 적합
	- 업로드 이미지 파일을 접수받는 웹 애플리케이션에 적합

### 그 외 스토리지
- 하테나에서 사용한 적이 있는 NFS, WebDAV, DRBD, HDFS에 대해 소개

#### NFS 계열 분산 파일시스템
- NFS는 특정 서버의 파일시스템을 다른 서버에서 마운트해서 해당 서버의 로컬 파일시스템과 마찬가지로 조작할 수 있도록 하는 기술.
	- 대부분의 UNIX 시스템에 구현되어 있으며, 간단하게 사용할 수 있는 점이 특징
	- 커널 레벨에서 구현되어 있는 경우가 많아 서버 측에 장애가 발생하면 클라이언트의 동작도 같이 정지
- 개선 버전으로 `GlusterFS` `Lustre` 등이 있음 (과학 기술 계산용으로 만들어져 큰 파일을 다룰때 좋음)

#### WebDAV 서버
- HTTP를 기반으로 한 프로토콜, 애플리케이션 계층에서 구현되는 경우가 많아 보다 안정적인 시스템 구축
	- 장애가 발생해도 서버 측 장애가 클라이언트도 정지되지 않음
- WebDAV 스토리지도 보통 마운트할 수 없어 파일 조작을 위해서는 애플리케이션을 손 볼 필요가 있음

#### DRBD (Distributed Replicated Block Device)
- 네트워크 계층에서의 RAID라고 할 수 있는 기술
- 블록 디바이스 레벨에서 분산, 다중화 할 수 있는 기술

#### HDFS (Hadoop Distributed File System)
- Hadoop용으로 설계된 분산 파일시스템
- HDFS에서는 파일을 64MB씩 분할해서 저장, 수십MB ~ 수십GB의 거대한 데이터를 저장하는 것이 목적
- 기본적인 액세스로 Java API 경우로 되어 있으며 MapReduce를 대상으로 함

### 스토리지의 선택전략
<img src="../image/Pasted image 20250503020058.png" width="800" height="550">
- 선택을 하고 스토리지에 적절한 하드웨어 상에 구축하고 적절하게 설정, 튜닝할 필요가 있음

- - -
## 강의3: 캐시 시스템
### 웹 애플리케이션의 부하와 프록시/캐시 시스템
- 웹 애플리케이션의 부하가 서서히 증가해서 시스템 용량이 부족해졌을 때 AP 서버나 DB 서버를 증설함으로써 대응할 수 있지만, **HTTP 레벨의 캐싱을 수행하는 HTTP 가속기를 사용**함으로써 낮은 비용으로 효과가 높은 대책을 세울 수 있음
- HTTP 가속기는 `포워드 프록시`와 `리버스 프록시` 두 종류가 있음
- `포워드 프록시`: 클라이언트가 외부 서버에 액세스할 때 사이에 두는 프록시
- `리버스 프록시`: 외부의 클라이언트가 내부 서버에 액세스 할 때 사이에 두는 프록시
- 프록시에서는 요청에 대한 응답을 캐싱해둠으로 같은 요청이 왔을 때 캐싱해둔 응답을 반환하게 함
	- 리버스 프록시를 이용한 캐시 서버를 운영하면 효율적임

#### 리버스 프록시 캐시 서버
- Squid가 가장 유명 이후 생략
- Squid를 대체하기 위해 `nginx`나 `pound` `Varnish` 등이 개발 됨
- 하테나는 `Squid` `Varnish` 두 가지 사용
- Squid는 HTTP, HTTPS, FTP용 다기능 프록시, 강력한 캐시 기능을 갖고 있음
- 이후 정리 생략

#### 캐시 서버를 2단으로 구성해 확장성 높은 캐시 서버군을 구성할 수 있음
- CARP라고 하는 프로토콜에 따라 URL을 키로 적절한 Squid 캐시 서버로 전송

#### 캐시 서버의 최적의 용량
- `1초당 저장된 오브젝트수` * `오브젝트의 평균크기` * `오브젝트의 평균 유효시간(초)`으로 계산되는 크기 + 앞으로 성장을 고려한 여유분
	- 계산이 어려우므로 하테나의 경험치로는 텍스트 위주인 경우 수 GB, 미디어 위주는 수십~수백GB

#### 주의점
- 워밍업을 잘 해놓자.

### Varnish - 리버스 프록시에 특화 (생략)
- 재시작하면 모두 사라짐

- - -
## 강의4: 계산 클러스터 (Hadoop)
### 대량 로그 데이터의 병렬 처리
- 하테나 다이어리의 액세스 로그는 하루에 4GB 로그 1개월분이면 120GB
	- 월간 고유 사용자를 계산하려고 하면 이 로그를 한 번에 처리하는데, HDD I/O 성능이 평균 50Mbps라고 할 때 읽는데만 5시간 소요
	- 즉, 이를 빠르게 처리하기 위해 병렬처리가 가능한 계산 클러스터 필요

### MapReduce의 계산모델
- 하테나는 Hadoop이라는 MapReduce의 오픈소스 구현을 사용
- MapReduce는 구글이 발표한 계산 모델
- 다수의 계산 노드로 구성된 클러스터와 대량 데이터를 분산해서 저장하기 위한 분산 파일시스템으로 구성
- MapReduce의 계산 모델은 key와 value 쌍의 리스트를 입력 데이터로 해서 최종적으로 value의 리스트 출력
<img src="../image/Pasted image 20250503025756.png" width="800" height="400">

### Hadoop
- Hadoop은 Apache 프로젝트 중 하나로 MapReduce의 오픈소스 구현 중 하나
- 로그 분석 작업을 위해 Map 태스크로 분할, Reduce 태스크로 집약되어 처리

